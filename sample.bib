@article{GlobalCancer,
author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
title = {Global Cancer Statistics 2020: GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries},
journal = {CA: A Cancer Journal for Clinicians},
volume = {71},
number = {3},
pages = {209-249},
keywords = {burden, cancer, epidemiology, incidence, mortality},
doi = {https://doi.org/10.3322/caac.21660},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21660},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21660},
abstract = {Abstract This article provides an update on the global cancer burden using the GLOBOCAN 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7\%), followed by lung (11.4\%), colorectal (10.0 \%), prostate (7.3\%), and stomach (5.6\%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18\%), followed by colorectal (9.4\%), liver (8.3\%), stomach (7.7\%), and female breast (6.9\%) cancers. Overall incidence was from 2-fold to 3-fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied <2-fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47\% rise from 2020, with a larger increase in transitioning (64\% to 95\%) versus transitioned (32\% to 56\%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.},
year = {2021}
}



@article{Melanoma,
author = {Siegel, Rebecca L. and Miller, Kimberly D. and Jemal, Ahmedin},
title = {Cancer statistics, 2019},
journal = {CA: A Cancer Journal for Clinicians},
volume = {69},
number = {1},
pages = {7-34},
keywords = {cancer cases, cancer statistics, death rates, incidence, mortality},
doi = {https://doi.org/10.3322/caac.21551},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21551},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21551},
abstract = {Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data, available through 2015, were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data, available through 2016, were collected by the National Center for Health Statistics. In 2019, 1,762,450 new cancer cases and 606,880 cancer deaths are projected to occur in the United States. Over the past decade of data, the cancer incidence rate (2006-2015) was stable in women and declined by approximately 2\% per year in men, whereas the cancer death rate (2007-2016) declined annually by 1.4\% and 1.8\%, respectively. The overall cancer death rate dropped continuously from 1991 to 2016 by a total of 27\%, translating into approximately 2,629,200 fewer cancer deaths than would have been expected if death rates had remained at their peak. Although the racial gap in cancer mortality is slowly narrowing, socioeconomic inequalities are widening, with the most notable gaps for the most preventable cancers. For example, compared with the most affluent counties, mortality rates in the poorest counties were 2-fold higher for cervical cancer and 40\% higher for male lung and liver cancers during 2012-2016. Some states are home to both the wealthiest and the poorest counties, suggesting the opportunity for more equitable dissemination of effective cancer prevention, early detection, and treatment strategies. A broader application of existing cancer control knowledge with an emphasis on disadvantaged groups would undoubtedly accelerate progress against cancer.},
year = {2019}
}


@ARTICLE{ThresholdBased,
  author={Thanh, Dang N.H. and Erkan, UÄŸur and Prasath, V.B. Surya and Kumar, Vivek and Hien, Nguyen Ngoc},
  journal={2019 6th International Conference on Electrical and Electronics Engineering (ICEEE)}, 
  title={A Skin Lesion Segmentation Method for Dermoscopic Images Based on Adaptive Thresholding with Normalization of Color Models}, 
  year={2019},
  volume={},
  number={},
  pages={116-120},
  keywords={Image segmentation;Skin;Image color analysis;Lesions;Adaptation models;Thresholding (Imaging);Measurement;skin lesion;skin cancer;melanoma;image segmentation;medical image segmentation;image processing},
  doi={10.1109/ICEEE2019.2019.00030}}


@MISC{Hao:gidmaps:2014,
  author = {Hao, Z. and AghaKouchak, A. and Nakhjiri, N. and Farahmand, A},
  year = {2014},
  title = {Global integrated drought monitoring and prediction system ({GIDMaPS}) data sets},
  howpublished = {\emph{figshare} \url{http://dx.doi.org/10.6084/m9.figshare.853801}}
}

@article{GraphCut,
title = {Multi-scale contrast based skin lesion segmentation in digital images},
journal = {Optik},
volume = {185},
pages = {794-811},
year = {2019},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2019.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0030402619304917},
author = {Idir Filali and Malika Belkadi},
keywords = {Melanoma, Multi-scale segmentation, Feature relevance, Hierarchical inference, Contrast estimation},
abstract = {Segmentation is the first step in computer-aided prescreening of melanoma diagnosis. It is therefore important to perform an accurate segmentation to delineate efficiently the lesion borders. This paper proposes a contrast based algorithm for segmenting skin lesions in digital photographs. After a decomposition of the image into superpixels, we introduce a regional similarity which considers histogram based difference supported by occurrence probability calculation and spatial coherence. This metric is then used to compute the regional background connectivity as the overlapping rate with image borders which serves to discard efficiently background regions and estimate the regional contrast. Thereafter, we improve the contrast accuracy through a feature weighting scheme that controls the contribution of each feature according to its relevance. To deal with the scale variation of lesions and some areas in the image, we define a hierarchical inference process that optimizes the lesion/background distinctiveness. Our algorithm is simple, multi-scale structured and resistant to image artifacts. Experiments on two standard datasets show that our approach yields accurate lesion segmentation and outperforms some recent state-of-the-art methods that provide high segmentation rates.}
}

@Article{SVM,
author={Akram, Tallha
and Khan, Muhammad Attique
and Sharif, Muhammad
and Yasmin, Mussarat},
title={Skin lesion segmentation and recognition using multichannel saliency estimation and M-SVM on selected serially fused features},
journal={Journal of Ambient Intelligence and Humanized Computing},
year={2024},
month={Jan},
day={01},
volume={15},
number={1},
pages={1083-1102},
abstract={The number of deaths caused by melanoma has increased remarkably in the last few years which are the carcinogenic type of skin cancer. Lately, computer based methods are introduced which are intelligent enough to support dermatologist in initial judgment of skin lesion. However, there still exists a gap for an optimal solution; therefore, machine learning community is still considering it a great challenge. The primary objective of this article is to efficiently detect and classify skin lesion with the utilization of an improved segmentation and feature selection criteria. Presented contribution is threefold; First, ternary color spaces are exploited to separate foreground from the background---utilizing multilevel approach of contrast stretching. Second, a weighting criterion is designed which is able to select the best solution based on extended texture feature analysis, related labels, boundary connections and central distance. Third, an improved feature extraction and dimensionality reduction criteria is proposed which combines conventional as well as recent feature extraction techniques. The proposed method is tested on PH2, ISBI 2016 and ISIC benchmark data sets and evaluated on the basis of multiple parameters including FPR, sensitivity, specificity, FNR and accuracy. From the statistics, it is quite clear that the proposed method outperforms numerous existing techniques with considerable margin.},
issn={1868-5145},
doi={10.1007/s12652-018-1051-5},
url={https://doi.org/10.1007/s12652-018-1051-5}
}

@article{FCN,
author="Adegun, Adekanmi
and Viriri, Serestina",
editor="Karray, Fakhri
and Campilho, Aur{\'e}lio
and Yu, Alfred",
title="Deep Learning Model for Skin Lesion Segmentation: Fully Convolutional Network",
journal="Image Analysis and Recognition",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="232--242",
abstract="Segmentation of skin lesions is a crucial task in detecting and diagnosing melanoma cancer. Incidence of melanoma skin cancer which is the most deadly form of skin cancer has been on steady increase. Early detection of the melanoma cancer is necessary to improve the survival rate of the patients. Segmentation is an important task in analysing skin lesion images. Skin lesion segmentation has come with some challenges such as low contrast and fine grained nature of skin lesions. This has necessitated the need for automated analysis and segmentation of skin lesions using state-of-the-arts techniques. In this paper, a deep learning model has been adapted for the segmentation of skin lesions. This work demonstrates the segmentation of skin lesions using fully convolutional networks (FCNs) that train skin lesion images from end-to-end using only the images pixels and disease ground truth labels as inputs. The fully convolutional network adapted is based on U-Net architecture. The model is enhanced by employing multi-stage segmentation approach with batch normalisation and data augmentation. Performance metrics such as dice coefficient, accuracy, sensitivity and specificity were used for evaluating the performance of the model. Experimental results show that the proposed model achieved better performance compared with the other state-of-the arts methods for skin lesion image segmentation with a dice coefficient of {\$}{\$}90{\backslash}{\%}{\$}{\$}and sensitivity of {\$}{\$}96{\backslash}{\%}{\$}{\$}.",
isbn="978-3-030-27272-2"
}

@article{UNet,
  author={Liu, Lina and Mou, Lichao and Zhu, Xiao Xiang and Mandal, Mrinal},
  journal={2019 IEEE Canadian Conference of Electrical and Computer Engineering (CCECE)}, 
  title={Skin Lesion Segmentation Based on Improved U-net}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  keywords={Skin;Image segmentation;Lesions;Melanoma;Training;Convolution;Deep learning;Skin Lesion Segmentation;U-net;Dilated Convolution},
  doi={10.1109/CCECE.2019.8861848}}

@article{Segnet,
author={{\c{S}}ahin, Nurullah
and Alpaslan, Nuh
and Hanbay, Davut},
title={Robust optimization of SegNet hyperparameters for skin lesion segmentation},
journal={Multimedia Tools and Applications},
year={2022},
month={Oct},
day={01},
volume={81},
number={25},
pages={36031-36051},
abstract={Melanoma is considered the deadliest form of skin cancer, and the number of cases is increasing day by day. The early diagnosis of melanoma is critical, as it significantly increases the patient's chance of survival. However, distinguishing melanoma from other skin lesion types by the physician can be a complicated process due to the diversity of its structural and textural features. Numerous computer-aided diagnosis (CAD) systems have been developed to assist the physician in detecting melanoma during recent years. The segmentation is a critical step for CAD systems, as it directly contributes to the performance of both feature extraction and classification steps. The optimization of the hyperparameters of deep learning methods is a challenging research topic. In this paper, the Bayesian optimized SegNet approach is proposed for precise skin lesion segmentation. The proposed method is obtained competitive results with the latest skin lesion segmentation methods. The hyperparameters optimized SegNet has achieved the best results with the average Jaccard Index of 84.9 on ISBI2016 and 74.5 on ISBI2017 dataset. Experimental results indicate the validity of Bayesian optimized SegNet. In this study, it has been observed that the bayesian hyperparameter optimization in the SegNet, which is the latest deep learning architecture, increased the segmentation performance of the SegNet by 16{\%} in the ISBI2016 dataset and by 7{\%} in the ISBI2017 dataset.},
issn={1573-7721},
doi={10.1007/s11042-021-11032-6},
url={https://doi.org/10.1007/s11042-021-11032-6}
}

@article{Deeplab,
title = {Skin lesion segmentation from dermoscopic images by using Mask R-CNN, Retina-Deeplab, and graph-based methods},
journal = {Biomedical Signal Processing and Control},
volume = {67},
pages = {102533},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102533},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421001300},
author = {Fatemeh Bagheri and Mohammad Jafar Tarokh and Majid Ziaratban},
keywords = {Lesion segmentation, Mask R-CNN, RetinaNet, Deeplab, Geodesic, Graph},
abstract = {Background and objective
Timely diagnosis of skin cancer which is one of the most common cancers can greatly prevent death. Automatic skin lesion segmentation is an important part of an automatic skin cancer diagnosis system. Due to the wide variety in color, location, size, shape, and boundary contrast of lesions, the lesion segmentation is still a challenging problem.
Methods
In this study, we present a two-stage automatic skin lesion segmentation method. In the first stage, a detection-based segmentation structure, Retina-Deeplab, is proposed to be combined with the Mask R-CNN, which inherently detects and segments objects simultaneously. To combine the results of these two segmentation methods, two geodesic-based and graph-based combination approaches are proposed.
Results
The proposed method is evaluated using three well-known skin image datasets (ISBI 2017, DermQuest, and PH2). Through the proposed two-step graph-based combination strategy, the Jaccard value of the overall lesion segmentation method reached 80.04%, which is 3.54% higher than the winner of the ISBI 2017 lesion segmentation challenge.
Conclusions
The proposed Retina-Deeplab segmentation method reached about 1% of the Jaccard value higher than the Mask R-CNN. Our overall segmentation method considered both overall characteristics of lesions in all images (by using CNN-based methods in the first stage) and image-specific features of lesions (by using geodesic-based/graph-based combination approaches in the second stage). The proposed two-step geodesic-based and graph-based combination approaches performed better than earlier combination strategies. Experiments demonstrated that the overall proposed lesion segmentation methods outperformed other state-of-the-art methods on well-known datasets.}
}

@article{GAN,
title = {Skin lesion segmentation via generative adversarial networks with dual discriminators},
journal = {Medical Image Analysis},
volume = {64},
pages = {101716},
year = {2020},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101716},
url = {https://www.sciencedirect.com/science/article/pii/S1361841520300803},
author = {Baiying Lei and Zaimin Xia and Feng Jiang and Xudong Jiang and Zongyuan Ge and Yanwu Xu and Jing Qin and Siping Chen and Tianfu Wang and Shuqiang Wang},
keywords = {Skin lesion segmentation, Generative adversarial network, Dense convolution U-Net, Dual discriminators},
abstract = {Skin lesion segmentation from dermoscopy images is a fundamental yet challenging task in the computer-aided skin diagnosis system due to the large variations in terms of their views and scales of lesion areas. We propose a novel and effective generative adversarial network (GAN) to meet these challenges. Specifically, this network architecture integrates two modules: a skip connection and dense convolution U-Net (UNet-SCDC) based segmentation module and a dual discrimination (DD) module. While the UNet-SCDC module uses dense dilated convolution blocks to generate a deep representation that preserves fine-grained information, the DD module makes use of two discriminators to jointly decide whether the input of the discriminators is real or fake. While one discriminator, with a traditional adversarial loss, focuses on the differences at the boundaries of the generated segmentation masks and the ground truths, the other examines the contextual environment of target object in the original image using a conditional discriminative loss. We integrate these two modules and train the proposed GAN in an end-to-end manner. The proposed GAN is evaluated on the public International Skin Imaging Collaboration (ISIC) Skin Lesion Challenge Datasets of 2017 and 2018. Extensive experimental results demonstrate that the proposed network achieves superior segmentation performance to state-of-the-art methods.}
}

@article{AttentionGates,
title = {Automated skin lesion segmentation using attention-based deep convolutional neural network},
journal = {Biomedical Signal Processing and Control},
volume = {65},
pages = {102358},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2020.102358},
url = {https://www.sciencedirect.com/science/article/pii/S1746809420304663},
author = {Ridhi Arora and Balasubramanian Raman and Kritagya Nayyar and Ruchi Awasthi},
keywords = {Skin lesion, Lesion detection, Attention gate, Deep learning, Image segmentation, Feature extraction},
abstract = {Edge detection for dermoscopic images has always been a crucial task for automatic lesion delineation processes. A skin lesion is an area of the skin that takes the form an abnormal growth or appearance when compared to the skin surrounding it. The abnormal appearance is the colored area of the skin that is advised for urgent referral and treatment. The manual way of diagnosing the disease is time-consuming and not quantifiable. However, computer-aided diagnosis (CADx)-based treatment can provide aid to manual delineation by the experts in diagnosing the disease with more proficiency. To advance the digital process of segmentation, a deep learning-based end-to-end framework is proposed for automatic dermoscopic image segmentation. The framework has the modified form of U-Net, which effectively uses Group Normalization (GN) in the encoder and the decoder layers. Attention Gates (AG) focusing on minute details in the skip connection later incorporates with Tversky Loss (TL) as the output loss function are added. Instead of Batch Normalization (BN), GN is used to extract the feature maps generated by the encoding path efficiently. To distinguish high dimensional information from low-level irrelevant background regions in the input image, AGs are used. Tversky Index (TI)-based TL is applied to accomplish better alliance between recall and precision. To further strengthen feature propagation and encourage feature reuse, atrous convolutions are applied in the connecting bridge between the encoder path and the decoder path of the network. The proposed model is evaluated on the ISIC 2018 image dataset, outshone the state-of-the-art segmentation methods.}
}

@article{Transformer,
title = {FAT-Net: Feature adaptive transformers for automated skin lesion segmentation},
journal = {Medical Image Analysis},
volume = {76},
pages = {102327},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102327},
url = {https://www.sciencedirect.com/science/article/pii/S1361841521003728},
author = {Huisi Wu and Shihuai Chen and Guilian Chen and Wei Wang and Baiying Lei and Zhenkun Wen},
keywords = {Feature adaptive transformer, Convolutional neural networks, Skin lesion segmentation, Memory-efficient decoder},
abstract = {Skin lesion segmentation from dermoscopic image is essential for improving the quantitative analysis of melanoma. However, it is still a challenging task due to the large scale variations and irregular shapes of the skin lesions. In addition, the blurred lesion boundaries between the skin lesions and the surrounding tissues may also increase the probability of incorrect segmentation. Due to the inherent limitations of traditional convolutional neural networks (CNNs) in capturing global context information, traditional CNN-based methods usually cannot achieve a satisfactory segmentation performance. In this paper, we propose a novel feature adaptive transformer network based on the classical encoder-decoder architecture, named FAT-Net, which integrates an extra transformer branch to effectively capture long-range dependencies and global context information. Furthermore, we also employ a memory-efficient decoder and a feature adaptation module to enhance the feature fusion between the adjacent-level features by activating the effective channels and restraining the irrelevant background noise. We have performed extensive experiments to verify the effectiveness of our proposed method on four public skin lesion segmentation datasets, including the ISIC 2016, ISIC 2017, ISIC 2018, and PH2 datasets. Ablation studies demonstrate the effectiveness of our feature adaptive transformers and memory-efficient strategies. Comparisons with state-of-the-art methods also verify the superiority of our proposed FAT-Net in terms of both accuracy and inference speed. The code is available at https://github.com/SZUcsh/FAT-Net.}
}

@article{Mamba,
author="Nguyen, Viet-Thanh
and Pham, Van-Truong
and Tran, Thi-Thao",
editor="Huang, Yo-Ping
and Wang, Wen-June
and Le, Hieu-Giang
and Hoang, An-Quoc",
title="AC-MambaSeg: An Adaptive Convolution and Mamba-Based Architecture for Enhanced Skin Lesion Segmentation",
journal="Computational Intelligence Methods for Green Technology and Sustainable Development",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="13--26",
abstract="Skin lesion segmentation is a critical task in computer-aided diagnosis systems for dermatological diseases. Accurate segmentation of skin lesions from medical images is essential for early detection, diagnosis, and treatment planning. In this paper, we propose a new model for skin lesion segmentation namely AC-MambaSeg, an enhanced model that has the hybrid CNN-Mamba backbone and integrates advanced components such as Convolutional Block Attention Module (CBAM), Attention Gate, and Selective Kernel Bottleneck. AC-MambaSeg leverages the VMamba framework for efficient feature extraction, while CBAM and Selective Kernel Bottleneck enhance its ability to focus on informative regions and suppress background noise. We evaluate the performance of AC-MambaSeg on diverse datasets of skin lesion images including ISIC2018 and PH2; then compare it against existing segmentation methods. Our model shows promising potential for improving computer-aided diagnosis systems and facilitating early detection and treatment of dermatological diseases. Our source code is available at: https://github.com/vietthanh2710/AC-MambaSeg.",
isbn="978-3-031-76197-3"
}